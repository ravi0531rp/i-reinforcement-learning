{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heisenberg/anaconda3/envs/RL/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discrete(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(Discrete(3).sample())\n",
    "print(Discrete(3).sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([[0. 0. 0.]\n",
       " [0. 0. 0.]\n",
       " [0. 0. 0.]], [[1. 1. 1.]\n",
       " [1. 1. 1.]\n",
       " [1. 1. 1.]], (3, 3), float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0,1, shape=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94578344, 0.76487947, 0.4459085 ],\n",
       "       [0.62333924, 0.8586406 , 0.60429865],\n",
       "       [0.8265448 , 0.27512774, 0.6257228 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0,1, shape=(3,3)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4730486 , 0.66486526, 0.9345994 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0,1, shape=(3,)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([0.3951616 , 0.28509513, 0.78273046], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tuple((Discrete(3) , Box(0,1, shape=(3,)))).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('height', 2),\n",
       "             ('speed',\n",
       "              array([0.37094456, 0.9452412 , 0.63419867], dtype=float32))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict({'height':Discrete(3) ,'speed': Box(0,1, shape=(3,))}).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiBinary(4).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  0 33]\n",
      "[ 4  0 99]\n",
      "[ 3  0 31]\n"
     ]
    }
   ],
   "source": [
    "print(MultiDiscrete([5,2,100]).sample())\n",
    "print(MultiDiscrete([5,2,100]).sample())\n",
    "print(MultiDiscrete([5,2,100]).sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an Environment\n",
    "* Build an Agent to give us the best shower possible\n",
    "* Randomly Temperature Fluctuates\n",
    "* We want temp b/w 37 & 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90.41883], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0 , 100, shape = (1,)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(3) # Turn temp up, down or keep it as it is\n",
    "        self.observation_space = Box(0 , 100, shape=(1,)) # temp can be from 0 to 100\n",
    "        self.state = 38 + random.randint(-3, 3) # initial state\n",
    "        self.shower_length = 60\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        self.state += action #- 1\n",
    "        self.shower_length -= 1\n",
    "\n",
    "        if self.state >= 37 and self.state <=39:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "\n",
    "        if self.shower_length <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        info = {}\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.array([38 + random.randint(-3, 3)]).astype(float)\n",
    "        self.shower_length = 60\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.9859], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48.]\n",
      "2\n",
      "[50.] -1 False {}\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(env.state)\n",
    "curr_act = env.action_space.sample()\n",
    "print(curr_act)\n",
    "obs, reward, done, info = env.step(curr_act)\n",
    "print(obs, reward, done, info)\n",
    "print(env.shower_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 ended with score -60\n",
      "Episode 2 ended with score -58\n",
      "Episode 3 ended with score -60\n",
      "Episode 4 ended with score -60\n",
      "Episode 5 ended with score -54\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f\"Episode {episode} ended with score {score}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('./train-artifacts', 'logs')\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log= log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./train-artifacts/logs/PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -56.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 454      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -57         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 447         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007611882 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.00731     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.23        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -57.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 445          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047203433 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.000171    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | 0.000379     |\n",
      "|    value_loss           | 67.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -56.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 443         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010598782 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -9.16e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.000407   |\n",
      "|    value_loss           | 74          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -56.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 443         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004929254 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 7.27e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.8        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.000579   |\n",
      "|    value_loss           | 86.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -56.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 442         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011270184 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0255      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    value_loss           | 93          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -56.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 443         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007866827 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.0723      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46          |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 0.000203    |\n",
      "|    value_loss           | 96.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -56.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 443         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014320681 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    value_loss           | 97.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -56.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 439          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067498386 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.161        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.7         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    value_loss           | 91.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -56.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 438          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016303725 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.207        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.6         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000122    |\n",
      "|    value_loss           | 90.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -56.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 439          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012369474 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 49.4         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -2.69e-05    |\n",
      "|    value_loss           | 85.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -56.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 439          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073141423 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.311        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    value_loss           | 82.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -56.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 439          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0144977495 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.359        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50.4         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    value_loss           | 77.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -56.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 439          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072070784 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | 0.000166     |\n",
      "|    value_loss           | 69.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -56.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 439          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043230625 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000449    |\n",
      "|    value_loss           | 63.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -56.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 440          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092897955 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 58.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -56.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 440         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012552751 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -57         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 440         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008989478 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -57.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 440         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005081041 |\n",
      "|    clip_fraction        | 0.000586    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.000768   |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -57.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 441        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01186195 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.949     |\n",
      "|    explained_variance   | 0.79       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13         |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.00532   |\n",
      "|    value_loss           | 27.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -58         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 441         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008319883 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.825       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.2         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -58.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 441         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008001795 |\n",
      "|    clip_fraction        | 0.0481      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.06        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -57.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 440         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009549793 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.99        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -57.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 440        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 111        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00322119 |\n",
      "|    clip_fraction        | 0.0483     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.974     |\n",
      "|    explained_variance   | 0.883      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.52       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.00265   |\n",
      "|    value_loss           | 15.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -57.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 440         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014863392 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.95       |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.74        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f10940c2100>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('./train-artifacts','saved_models','CustomEnvBasic')\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heisenberg/anaconda3/envs/RL/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-60.0, 0.0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('RL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51a43fc96a3e663f1abdbe53e6c5b190f2635013f992494f0bb741e169ee45b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
